{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ks6vLaEIvpPW"
   },
   "source": [
    "# **Identificación de Imágenes Auténticas y Sintéticas : Abordando los Desafíos de las Imágenes Sintéticas en la Sociedad Actual**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb4qq8PqUy1C"
   },
   "source": [
    "**Contenido**\n",
    "1. [Configuración del Entorno](#title1)\n",
    "2. [Construcción del Conjunto de Datos](#title2)\n",
    "3. [Creación del Modelo](#title3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glMN5HvjVDTW"
   },
   "source": [
    "## Configuración del Entorno<a name=\"title1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2.10.0\n",
      "Configuración de GPU completada\n",
      "¿GPU está disponible?: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.experimental.list_physical_devices(\"GPU\"))\n",
    "print(tf.__version__)\n",
    "# Para limitar la memoria que usa la GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Configurar TensorFlow para que solo utilice la GPU si es necesario\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Configuración de GPU completada\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "# Verifica que la GPU está disponible\n",
    "print(\"¿GPU está disponible?:\", tf.config.list_physical_devices('GPU'))\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# Limpiar la memoria del backend\n",
    "K.clear_session()\n",
    "# Forzar la recolección de basura\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpiar la memoria del backend\n",
    "K.clear_session()\n",
    "# Forzar la recolección de basura\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 9701,
     "status": "ok",
     "timestamp": 1731341832412,
     "user": {
      "displayName": "Deciré Jaimes",
      "userId": "01417579230318043908"
     },
     "user_tz": 300
    },
    "id": "4nGU9yscxo7n"
   },
   "outputs": [],
   "source": [
    "# Importar todas las librerías de uso.\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qxgLE4aWYZ1"
   },
   "source": [
    "## Construcción del Conjunto de Datos y Preprocesandolos<a name=\"title2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Si1mUNfNhef9"
   },
   "source": [
    "Fuente: https://www.kaggle.com/datasets/kaustubhdhote/human-faces-dataset & https://www.kaggle.com/datasets/hamzaboulahia/hardfakevsrealfaces/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 184,
     "status": "ok",
     "timestamp": 1731341920891,
     "user": {
      "displayName": "Deciré Jaimes",
      "userId": "01417579230318043908"
     },
     "user_tz": 300
    },
    "id": "Z_zqm-Lo9oFa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10919 files belonging to 2 classes.\n",
      "Clases: ['Fake', 'Real']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parámetros\n",
    "batch_size = 32\n",
    "img_height = 224  # Requerido por EfficientNetB0\n",
    "img_width = 224\n",
    "initial_epochs = 10\n",
    "fine_tune_epochs = 10\n",
    "\n",
    "# Directorio de datos\n",
    "data_folder = './Data/All'\n",
    "\n",
    "# Cargar el dataset completo\n",
    "full_dataset = image_dataset_from_directory(\n",
    "    data_folder,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=None,  # Cargar todas las imágenes individualmente\n",
    "    shuffle=True,\n",
    "    seed=123  # Semilla para reproducibilidad\n",
    ")\n",
    "\n",
    "# Obtener el tamaño total del dataset\n",
    "dataset_size = full_dataset.cardinality().numpy()\n",
    "\n",
    "# Definir tamaños para entrenamiento, validación y prueba\n",
    "train_size = int(0.7 * dataset_size)\n",
    "val_size = int(0.15 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "# Dividir el dataset\n",
    "train_dataset = full_dataset.take(train_size)\n",
    "remaining = full_dataset.skip(train_size)\n",
    "validation_dataset = remaining.take(val_size)\n",
    "test_dataset = remaining.skip(val_size)\n",
    "\n",
    "# Agrupar los datasets\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "validation_dataset = validation_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "# Capturar class_names\n",
    "class_names = full_dataset.class_names\n",
    "print(\"Clases:\", class_names)\n",
    "\n",
    "# Aplicar prefetch\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 112, 112, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 56, 56, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 56, 56, 3)         387       \n",
      "                                                                 \n",
      " up_sampling2d_21 (UpSamplin  (None, 224, 224, 3)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76,035\n",
      "Trainable params: 76,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# **Definir el Autoencoder**\n",
    "\n",
    "# Codificador\n",
    "input_img = layers.Input(shape=(img_height, img_width, 3))\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)  # (112, 112, 64)\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)  # (56, 56, 128)\n",
    "\n",
    "# Reescalar las salidas del codificador a (224, 224, 3)\n",
    "decoded = layers.Conv2D(3, (1, 1), activation='relu', padding='same')(encoded)  # Reducir canales a 3\n",
    "decoded = layers.UpSampling2D((4, 4))(decoded)  # Escalar de (56, 56) a (224, 224, 3)\n",
    "\n",
    "# Autoencoder\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()\n",
    "\n",
    "# Codificador para extraer características\n",
    "encoder = Model(input_img, decoded)\n",
    "\n",
    "# **Construcción del modelo de clasificación**\n",
    "encoded_inputs = encoder(input_img) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fy07St2fSjpW"
   },
   "source": [
    "# Modelo<a name=\"title3\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jVpkCu8cHs9L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " model_16 (Functional)       (None, 224, 224, 3)       76035     \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               163968    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,289,703\n",
      "Trainable params: 240,132\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Usar EfficientNetB0\n",
    "x = preprocess_input(encoded_inputs)  # Preprocesamiento específico para EfficientNet\n",
    "base_model = EfficientNetB0(input_shape=(img_height, img_width, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "# Capas superiores del clasificador\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.005))(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)  # Clasificación binaria\n",
    "\n",
    "# Construcción del modelo completo\n",
    "model = Model(input_img, outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mzar0BhcHvzR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos de clase: {0: 1.0228854389721627, 1: 0.9781162016892757}\n",
      "Epoch 1/10\n",
      "239/239 [==============================] - 50s 189ms/step - loss: 0.5235 - accuracy: 0.9368 - val_loss: 0.2385 - val_accuracy: 0.9597 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "134/239 [===============>..............] - ETA: 17s - loss: 0.2149 - accuracy: 0.9569"
     ]
    }
   ],
   "source": [
    "# Calcular pesos de clase\n",
    "y_train = np.concatenate([y for x, y in train_dataset], axis=0)\n",
    "class_weights_values = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights_values))\n",
    "print(f\"Pesos de clase: {class_weights}\")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Entrenar el modelo con pesos de clase\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=initial_epochs,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Fine-Tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = 100\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=initial_epochs + fine_tune_epochs,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas\n",
    "true_labels = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "predictions = model.predict(test_dataset).ravel()\n",
    "\n",
    "# Ajustar el umbral óptimo\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Umbral Óptimo: {optimal_threshold}\")\n",
    "\n",
    "# Aplicar el umbral óptimo\n",
    "predicted_labels_optimal = (predictions > optimal_threshold).astype(int)\n",
    "\n",
    "# Matriz de Confusión con umbral óptimo\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels_optimal)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Etiqueta Predicha')\n",
    "plt.ylabel('Etiqueta Verdadera')\n",
    "plt.title('Matriz de Confusión con Umbral Óptimo')\n",
    "plt.show()\n",
    "\n",
    "# Reporte de Clasificación con umbral óptimo\n",
    "print(\"\\nReporte de Clasificación con Umbral Óptimo:\")\n",
    "print(classification_report(true_labels, predicted_labels_optimal, target_names=class_names))\n",
    "\n",
    "# Precisión Global con umbral óptimo\n",
    "accuracy_optimal = accuracy_score(true_labels, predicted_labels_optimal)\n",
    "print(f\"Precisión Global con Umbral Óptimo: {accuracy_optimal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(len(acc))\n",
    "    \n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Precisión Entrenamiento')\n",
    "    plt.plot(epochs_range, val_acc, label='Precisión Validación')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Precisión')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Pérdida Entrenamiento')\n",
    "    plt.plot(epochs_range, val_loss, label='Pérdida Validación')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Pérdida')\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
